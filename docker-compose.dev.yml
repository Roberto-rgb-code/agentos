services:
  # ============================================
  # PostgreSQL - Base de datos
  # ============================================
  postgres:
    image: postgres:16-alpine
    container_name: agentos-postgres
    environment:
      POSTGRES_USER: agentos
      POSTGRES_PASSWORD: agentos
      POSTGRES_DB: agentos_dev
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U agentos -d agentos_dev"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s
    networks:
      - agentos-net
    restart: unless-stopped

  # ============================================
  # Ollama - LLM local (IA)
  # ============================================
  ollama:
    image: ollama/ollama:latest
    container_name: agentos-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 20
      start_period: 60s
    networks:
      - agentos-net
    restart: unless-stopped

  # ============================================
  # Ollama Model Loader - Descarga modelos automaticamente
  # ============================================
  ollama-models:
    image: ollama/ollama:latest
    container_name: agentos-ollama-models
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "‚è≥ Descargando modelo LLM: phi3:mini ..."
        ollama pull phi3:mini
        echo "‚úÖ phi3:mini listo"
        echo "‚è≥ Descargando modelo embeddings: nomic-embed-text ..."
        ollama pull nomic-embed-text
        echo "‚úÖ nomic-embed-text listo"
        echo "üéâ Todos los modelos descargados!"
    environment:
      - OLLAMA_HOST=ollama:11434
    networks:
      - agentos-net

  # ============================================
  # Backend - Node.js API Server
  # ============================================
  server:
    build:
      context: .
      dockerfile: docker/Dockerfile.server
    container_name: agentos-server
    environment:
      NODE_ENV: production
      SERVER_PORT: 3001
      DATABASE_URL: "postgresql://agentos:agentos@postgres:5432/agentos_dev"
      JWT_SECRET: "agentos-secret-change-in-production"
      LLM_PROVIDER: ollama
      OLLAMA_BASE_PATH: http://ollama:11434
      OLLAMA_MODEL_PREF: phi3:mini
      EMBEDDING_ENGINE: ollama
      EMBEDDING_BASE_PATH: http://ollama:11434
      EMBEDDING_MODEL_PREF: nomic-embed-text
      STORAGE_DIR: /app/storage
      SEED_ADMIN_EMAIL: admin
      SEED_ADMIN_PASSWORD: admin123
    ports:
      - "3001:3001"
    volumes:
      - server_storage:/app/storage
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - agentos-net
    restart: unless-stopped

  # ============================================
  # Frontend - React + Nginx
  # ============================================
  frontend:
    build:
      context: .
      dockerfile: docker/Dockerfile.frontend
    container_name: agentos-frontend
    ports:
      - "3000:3000"
    depends_on:
      - server
    networks:
      - agentos-net
    restart: unless-stopped

  # ============================================
  # n8n - Workflow Automation
  # ============================================
  n8n:
    image: n8nio/n8n:latest
    container_name: agentos-n8n
    environment:
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:5678
      - NODE_FUNCTION_ALLOW_EXTERNAL=*
      - N8N_SECURE_COOKIE=false
      - N8N_PERSONALIZATION_ENABLED=false
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - agentos-net
    restart: unless-stopped

volumes:
  postgres_data:
  server_storage:
  n8n_data:
  ollama_data:

networks:
  agentos-net:
    driver: bridge
